{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c483e597",
   "metadata": {},
   "source": [
    "## Number 6\n",
    "Picking up from the discussion of simultaneous equations above, where y is N x k, and $y = X\\beta{}\\ + u$  \n",
    "If X is N x l and cov(u|X) = $\\Omega{}\\$ then this is a generalization of the assumption of homoskedasticity to a multivariate setting; the resulting structure is called a system of Seemingly Unrelated Regressions (SUR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048c66d",
   "metadata": {},
   "source": [
    "(i) If $\\Omega{}\\$ isn't diagonal then there's a sense in which the different\n",
    "equations in the system are dependent, since observing a realization of, say, y1 may change our prediction of y2. (This is why the system is called seemingly unrelated.) Describe this dependence formally."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b2c588b",
   "metadata": {},
   "source": [
    "If omega is not diagonal and the equations in the system are dependent, that means the errors are correlated across equations. To tackle this problem, we may consider estimation by Generalized Least Squares (GLS) which we will premultiply by $\\Omega^{^-1/2}$ so that the transformed vector is independent and identically distributed. \n",
    "\n",
    "$y=\\bar{X}\\cdot\\beta{}+e$\n",
    "\n",
    "$E[e|X] = 0$\n",
    "\n",
    "$E[ee'|X] = \\Omega{}\\$\n",
    "\n",
    "$\\hat{\\beta}{_g}{_l}{_s} = (\\sum_{i=1}^{n}\\bar{X_i}'\\sum^{-1}\\bar{X_i})^{-1}(\\sum_{i=1}^{n}\\bar{X_i}'\\sum^{-1}{Y_i})^{-1}$\n",
    "\n",
    "Since $\\Omega\\$ is unknown, it must be replaced by an estimator \n",
    "\n",
    "$E[ee'|X] = \\hat{\\Omega}\\$\n",
    "\n",
    "Using $\\hat{\\Omega}\\$, we obtain a feasible GLS estimator\n",
    "\n",
    "$\\hat{\\beta}{_s}{_u}{_r} = (\\sum_{i=1}^{n}\\bar{X_i}'\\hat{\\Omega^{-1}}\\bar{X_i})^{-1}(\\sum_{i=1}^{n}\\bar{X_i}'\\hat{\\Omega^{-1}}{Y_i})^{-1}$\n",
    "\n",
    "$ = (\\bar{X_i}{'}(I_n\\cdot\\hat{\\Omega^{-1}}\\bar{X})^{-1}(\\bar{X_i}{'}(I_n\\cdot\\hat{\\Omega^{-1}}Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c934bf4",
   "metadata": {},
   "source": [
    "(ii) Adapt the code in weighted_regression.ipynb so that the data-generating process for u can accommodate a general covariance matrix such as $\\Omega{}$, and let X = T. Estimate $\\beta{}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dee6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.linalg import inv, sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f40ec7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "import random\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34ff3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random variables \n",
    "k = 3 # Number of observables in T\n",
    "\n",
    "mu = [0]*k\n",
    "\n",
    "Sigma=[[1,0.5,0],\n",
    "       [0.5,2,0],\n",
    "       [0,0,3]]\n",
    "\n",
    "T = multivariate_normal(mu,Sigma)\n",
    "\n",
    "Omega = [[1,0.2],\n",
    "         [0.2,2]]  # covariance matrix for u\n",
    "\n",
    "u = multivariate_normal(mean=[0,0],cov=Omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eaeea1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and construct a sample\n",
    "beta = [1/2,1]\n",
    "\n",
    "D = np.random.random(size=(3,2)) # Generate random 3x2 matrix\n",
    "\n",
    "N=1000 # Sample size\n",
    "\n",
    "# Now: Transform rvs into a sample\n",
    "T = T.rvs(N)\n",
    "\n",
    "u = u.rvs(N) # Replace u with a sample\n",
    "\n",
    "X = (T**3)@D  # Note use of ** operator for exponentiation\n",
    "\n",
    "y = X@beta + u[:,0] # Note use of @ operator for matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "225758d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49544231 0.99470168]\n",
      "[[ 9.26048771e-05 -7.78176508e-05]\n",
      " [-7.78176508e-05  9.17867687e-05]]\n"
     ]
    }
   ],
   "source": [
    "# Estimate B\n",
    "Omega_inv = inv(Omega)\n",
    "W = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    W[i,i] = Omega_inv[0,0]\n",
    "b = np.linalg.lstsq(T.T @ W @ X, T.T @ W @ y, rcond=None)[0] # lstsqs returns several results\n",
    "\n",
    "e = y - X@b\n",
    "\n",
    "print(b)\n",
    "\n",
    "TXplus = np.linalg.pinv(T.T@ W @ X) # Moore-Penrose pseudo-inverse\n",
    "\n",
    "# Covariance matrix of b\n",
    "vb = e.var()*TXplus@T.T@ W @ W @ T@TXplus.T  # u is known to be homoskedastic\n",
    "\n",
    "print(vb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e182a9",
   "metadata": {},
   "source": [
    "(iii) How are the estimates obtained from this SUR system different from what one would obtain if one estimated equation by equation using OLS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9917bf81",
   "metadata": {},
   "source": [
    "The estimator, Omega-hat can be updated by calculating the SUR residuals and the covariance matrix. Substitued, we obtain an iterated SUR estimator  that can be iterated until convergence. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
