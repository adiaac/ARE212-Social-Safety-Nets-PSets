{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e38c2b2",
   "metadata": {},
   "source": [
    "Picking up from the discussion of simultaneous equations above, where y is N x k, and y = Xβ + u. If X is N x l and cov(u|X) = Ω; then this is a generalization of the assumption of homoskedasticity to a multivariate setting; the resulting structure is called a system of Seemingly Unrelated Regressions (SUR)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7111b7d5",
   "metadata": {},
   "source": [
    "(1) If Ω isn't diagonal then there's a sense in which the different equations in the system are dependent, since observing a realization of, say, y1 may change our prediction of y2. (This is why the system is called seemingly unrelated.) Describe this dependence formally.\n",
    "\n",
    "(Answer) If the covariance matrix, Ω, is not diagonal, then the errors in the different equations of the system are correlated. Since the errors in the two equations are no longer independent, observing a realization of y1 may change our prediction of y2. The joint probability density function of the errors, u, is no longer a product of independent normal densities but a multivariate normal density with covariance matrix Ω."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e9a6a",
   "metadata": {},
   "source": [
    "(2) Adapt the code in weighted_regression.ipynb so that the data-generating process for u can accommodate a general covariance matrix such as Ω, and let X = T. Estimate β.\n",
    "\n",
    "(Answer) To accommodate a general covariance matrix for u, we can modify the generate_data function to draw errors from a multivariate normal distribution with mean 0 and covariance matrix Ω instead of the identity matrix I. The code is as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60664d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "#to enable displaying plots in line\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "k = 3 # Number of observables in T\n",
    "\n",
    "mu = [0]*k  #mean of the multivariate normal distribution\n",
    "Sigma=[[1,0.5,0],\n",
    "       [0.5,2,0],\n",
    "       [0,0,3]]\n",
    "\n",
    "#Sigma is the covariance matrix\n",
    "\n",
    "T = multivariate_normal(mu,Sigma) #defining a multivariate normal distribution T\n",
    "u = multivariate_normal(cov=0.2) #defining a univariate normal distribution u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e3d6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = [1/2,1] # vector of coefficients that will be used to predict the response variable y\n",
    "\n",
    "D = np.random.random(size=(3,2)) # Generate random 3x2 matrix\n",
    "\n",
    "N=1000 # Sample size\n",
    "\n",
    "# Now: Transform rvs into a sample\n",
    "T = T.rvs(N)\n",
    "\n",
    "u = u.rvs(N) # Replace u with a sample\n",
    "\n",
    "X = (T**3)@D  # Note use of ** operator for exponentiation\n",
    "\n",
    "y = X@beta + u # Note use of @ operator for matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "135d8333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50189069 0.9981324 ]\n",
      "[[ 4.56001040e-06 -5.41981870e-06]\n",
      " [-5.41981870e-06  7.86523997e-06]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haril\\AppData\\Local\\Temp\\ipykernel_12248\\2814452630.py:3: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  b = np.linalg.lstsq(T.T@X,T.T@y)[0] # lstsqs returns several results\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import inv, sqrtm\n",
    "\n",
    "b = np.linalg.lstsq(T.T@X,T.T@y)[0] # lstsqs returns several results\n",
    "\n",
    "e = y - X@b\n",
    "\n",
    "print(b)\n",
    "\n",
    "TXplus = np.linalg.pinv(T.T@X) # Moore-Penrose pseudo-inverse\n",
    "\n",
    "# Covariance matrix of b\n",
    "vb = e.var()*TXplus@T.T@T@TXplus.T  # u is known to be homoskedastic\n",
    "\n",
    "print(vb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e69a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for SUR\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Define the parameters of the model\n",
    "k1 = 3 # Number of observables in T1\n",
    "k2 = 4 # Number of observables in T2\n",
    "mu1 = [0]*k1 # Mean of T1\n",
    "mu2 = [0]*k2 # Mean of T2\n",
    "Sigma1 = [[1,0.5,0.2], [0.5,2,0], [0.2,0,3]] # Covariance of T1\n",
    "Sigma2 = [[2,0,0,0.5], [0,1,0.2,0], [0,0.2,1,0], [0.5,0,0,3]] # Covariance of T2\n",
    "\n",
    "# Generate the predictor variables\n",
    "T1 = multivariate_normal(mu1, Sigma1)\n",
    "T2 = multivariate_normal(mu2, Sigma2)\n",
    "\n",
    "# Generate the error terms\n",
    "u1 = multivariate_normal(cov=0.2)\n",
    "u2 = multivariate_normal(cov=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3f4ee11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m u2 \u001b[38;5;241m=\u001b[39m u2\u001b[38;5;241m.\u001b[39mrvs(N) \n\u001b[0;32m     19\u001b[0m X1 \u001b[38;5;241m=\u001b[39m (T1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;129m@D\u001b[39m  \u001b[38;5;66;03m# Note use of ** operator for exponentiation\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m X2 \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mT2\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;129;43m@D\u001b[39;49m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Generate the response variables\u001b[39;00m\n\u001b[0;32m     23\u001b[0m y1 \u001b[38;5;241m=\u001b[39m X1 \u001b[38;5;241m@\u001b[39m beta1 \u001b[38;5;241m+\u001b[39m u1\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 4)"
     ]
    }
   ],
   "source": [
    "# for SUR\n",
    "\n",
    "beta1 = [1/2,1,-1] # Coefficients for T1\n",
    "beta2 = [1,-1/2,0,1] # Coefficients for T2\n",
    "rho = 0.5 # Correlation between the error terms\n",
    "\n",
    "D = np.random.random(size=(3,2)) # Generate random 3x2 matrix\n",
    "\n",
    "N=1000 # Sample size\n",
    "\n",
    "# Now: Transform rvs into a sample\n",
    "T1 = T1.rvs(N)\n",
    "T2 = T2.rvs(N)\n",
    "\n",
    "# Replace u with a sample\n",
    "u1 = u1.rvs(N) \n",
    "u2 = u2.rvs(N) \n",
    "\n",
    "X1 = (T1**3)@D\n",
    "X2 = (T2**3)@D \n",
    "\n",
    "# Generate the response variables\n",
    "y1 = X1 @ beta1 + u1\n",
    "y2 = X2 @ beta2 + u2\n",
    "\n",
    "#y2 = X2 @ beta2 + rho * u1 + np.sqrt(1 - rho**2) * u2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "befcb8d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m u2 \u001b[38;5;241m=\u001b[39m u2\u001b[38;5;241m.\u001b[39mrvs(N) \n\u001b[0;32m     19\u001b[0m X1 \u001b[38;5;241m=\u001b[39m (T1\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;129m@D\u001b[39m  \u001b[38;5;66;03m# Note use of ** operator for exponentiation\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m X2 \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mT2\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;129;43m@D\u001b[39;49m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Generate the response variables\u001b[39;00m\n\u001b[0;32m     23\u001b[0m y1 \u001b[38;5;241m=\u001b[39m X1 \u001b[38;5;241m@\u001b[39m beta1 \u001b[38;5;241m+\u001b[39m u1\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 4)"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import inv, sqrtm\n",
    "\n",
    "b = np.linalg.lstsq(T.T@X,T.T@y)[0] # lstsqs returns several results\n",
    "\n",
    "e = y - X@b\n",
    "\n",
    "print(b)\n",
    "\n",
    "TXplus = np.linalg.pinv(T.T@X) # Moore-Penrose pseudo-inverse\n",
    "\n",
    "# Covariance matrix of b\n",
    "vb = e.var()*TXplus@T.T@T@TXplus.T  # u is known to be homoskedastic\n",
    "\n",
    "print(vb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e84b05",
   "metadata": {},
   "source": [
    "(3) How are the estimates obtained from this SUR system different from what one would obtain if one estimated equation by equation using OLS?\n",
    "\n",
    "(Answer) The SUR estimator takes into account the correlation between the errors in the different equations. If we estimated each equation separately using OLS, we would be assuming that the errors are uncorrelated, which would lead to inefficient estimates. The SUR estimator, on the other hand, uses information from all the equations to obtain more efficient estimates. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688812c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
